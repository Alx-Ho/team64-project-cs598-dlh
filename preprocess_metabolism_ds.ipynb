{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import DataStructs\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import requests\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dataset_S02` from PNAS publication link: https://www.pnas.org/doi/suppl/10.1073/pnas.1803294115\n",
    "The original file is an XLSX file, so it is converted to CSV format and columns renamed \n",
    "\n",
    "'Sentences describing the reported drug-drug interactions' --> 'gt' \n",
    "\n",
    "'Data type used to optimize the DNN architecture' --> 'set'\n",
    "\n",
    "The resulting file is in 'data/ds_s2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ds = pd.read_csv('data/ds_s2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the initial testing, we will only train a model for DDI type 6 \"The metabolism of Drug b can be decreased when combined with Drug a.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabolism_ds = full_ds[full_ds['gt'].str.contains(\"metabolism\")].reset_index(drop=True)\n",
    "metabolism_ds = metabolism_ds[metabolism_ds['gt'].str.contains(\"decreased\")].reset_index(drop=True)\n",
    "# metabolism_ds.to_csv('data/metabolism_ds_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabolism_ds = pd.read_csv('data/metabolism_ds_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we extract Drug A and Drug B from the ground truth sentences from the data assuming the structure \"The metabolism of \\<Drug b> can be decreased when combined with \\<Drug a>.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_pattern = r\"The metabolism of (\\w+) can be decreased when combined with (\\w+)\\.\"\n",
    "\n",
    "# Extract drug identifiers\n",
    "metabolism_ds['drug_b'], metabolism_ds['drug_a'] = zip(*metabolism_ds['gt'].str.extract(regex_pattern).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would like to get the SMILES representation for each, which we can get from go.drugbank.com using the provided drugbank ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_drugs = pd.concat([metabolism_ds['drug_a'], metabolism_ds['drug_b']]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_smiles(db_drug_id):\n",
    "    \n",
    "    base_url = \"https://go.drugbank.com/structures/small_molecule_drugs/{}.smiles\"\n",
    "    url = base_url.format(db_drug_id)\n",
    "    \n",
    "    result = \"\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            result = response.text.strip()\n",
    "        else:\n",
    "            result = None\n",
    "    except Exception as e:\n",
    "        result = \"error\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "def fetch_smiles_df(db_drug_id_lst): \n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for idx, db_drug_id in enumerate(db_drug_id_lst): \n",
    "        smiles = fetch_smiles(db_drug_id)\n",
    "        if smiles != None or smiles != \"error\": \n",
    "            results[db_drug_id] = smiles\n",
    "            \n",
    "    results_df = pd.DataFrame(list(results.items()), columns=['db_drug_id', 'smiles'])\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_drug_smiles = fetch_smiles_df(unique_drugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_drug_smiles.to_csv(\"data/metabolism_db_drug_id_to_smiles.csv\", index=None)\n",
    "db_drug_smiles = pd.read_csv(\"data/metabolism_db_drug_id_to_smiles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging for drug_a\n",
    "metabolism_ds = metabolism_ds.merge(db_drug_smiles, left_on='drug_a', right_on='db_drug_id', how='left')\n",
    "metabolism_ds.rename(columns={'smiles': 'drug_a_smiles'}, inplace=True)\n",
    "metabolism_ds.drop(columns=['db_drug_id'], inplace=True)\n",
    "\n",
    "# Merging for drug_b\n",
    "metabolism_ds = metabolism_ds.merge(db_drug_smiles, left_on='drug_b', right_on='db_drug_id', how='left')\n",
    "metabolism_ds.rename(columns={'smiles': 'drug_b_smiles'}, inplace=True)\n",
    "metabolism_ds.drop(columns=['db_drug_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metabolism_ds.to_csv(\"data/true_metabolism_clean_ds.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset only contains positive cases of the indicated interaction, so we also create negative casees of the indicated interaction the model can learn from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8z/7jtl0mvn6c7gzb_016f_8kpw0000gn/T/ipykernel_53280/3187261494.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  non_interacting_pairs['drug_a_smiles'] = non_interacting_pairs['drug_a'].map(smiles_map)\n",
      "/var/folders/8z/7jtl0mvn6c7gzb_016f_8kpw0000gn/T/ipykernel_53280/3187261494.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  non_interacting_pairs['drug_b_smiles'] = non_interacting_pairs['drug_b'].map(smiles_map)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a set of all unique drugs\n",
    "all_drugs = set(metabolism_ds['drug_a']).union(set(metabolism_ds['drug_b']))\n",
    "\n",
    "# Step 2: Create all possible pairs\n",
    "all_possible_pairs = pd.DataFrame(product(all_drugs, all_drugs), columns=['drug_a', 'drug_b'])\n",
    "\n",
    "# Remove self-pairs (where a drug pairs with itself)\n",
    "all_possible_pairs = all_possible_pairs[all_possible_pairs['drug_a'] != all_possible_pairs['drug_b']]\n",
    "\n",
    "# Create a set of tuples for existing interactions considering both orderings\n",
    "interaction_set = set()\n",
    "for idx, row in metabolism_ds.iterrows():\n",
    "    interaction_set.add((row['drug_a'], row['drug_b']))\n",
    "    interaction_set.add((row['drug_b'], row['drug_a']))\n",
    "\n",
    "# Filter the dataframe to exclude any pairs found in the interaction set\n",
    "non_interacting_pairs = all_possible_pairs[\n",
    "    ~all_possible_pairs.apply(lambda x: (x['drug_a'], x['drug_b']) in interaction_set, axis=1)\n",
    "]\n",
    "\n",
    "# Step 3: Add SMILES Information\n",
    "# Map to get SMILES for each drug\n",
    "smiles_map = pd.concat([\n",
    "    metabolism_ds[['drug_a', 'drug_a_smiles']].rename(columns={'drug_a': 'drug', 'drug_a_smiles': 'smiles'}),\n",
    "    metabolism_ds[['drug_b', 'drug_b_smiles']].rename(columns={'drug_b': 'drug', 'drug_b_smiles': 'smiles'})\n",
    "]).drop_duplicates().set_index('drug')['smiles']\n",
    "\n",
    "# Add SMILES information to the non-interacting pairs\n",
    "non_interacting_pairs['drug_a_smiles'] = non_interacting_pairs['drug_a'].map(smiles_map)\n",
    "non_interacting_pairs['drug_b_smiles'] = non_interacting_pairs['drug_b'].map(smiles_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_interacting_pairs.to_csv('data/non_interacting_drug_pairs.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now combine the provided data and the negative examples we created to make our full dataset for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "interacting_pairs = pd.read_csv('data/true_metabolism_clean_ds.csv')\n",
    "interacting_pairs['interaction'] = 1\n",
    "interacting_pairs = interacting_pairs[~(interacting_pairs['drug_a_smiles'].isna() | interacting_pairs['drug_b_smiles'].isna())]\n",
    "\n",
    "# Load the non-interacting pairs dataset\n",
    "non_interacting_pairs = pd.read_csv('data/non_interacting_drug_pairs.csv')\n",
    "non_interacting_pairs['interaction'] = 0\n",
    "non_interacting_pairs = non_interacting_pairs[~(non_interacting_pairs['drug_a_smiles'].isna() | non_interacting_pairs['drug_b_smiles'].isna())]\n",
    "\n",
    "\n",
    "# Ensure the columns are aligned and in the same order\n",
    "columns = ['drug_a', 'drug_b', 'drug_a_smiles', 'drug_b_smiles', 'interaction']\n",
    "interacting_pairs = interacting_pairs[columns]\n",
    "non_interacting_pairs = non_interacting_pairs[columns]\n",
    "\n",
    "# Determine the smaller size\n",
    "min_size = min(len(interacting_pairs), len(non_interacting_pairs))\n",
    "\n",
    "# Randomly sample from the larger dataset\n",
    "non_interacting_sample = non_interacting_pairs.sample(n=min_size, random_state=42)  # Using a seed for reproducibility\n",
    "interacting_sample = interacting_pairs.sample(n=min_size, random_state=42)  # This step is usually not necessary unless interacting_pairs is also too large\n",
    "\n",
    "# Concatenate the balanced datasets\n",
    "balanced_dataset = pd.concat([interacting_sample, non_interacting_sample])\n",
    "\n",
    "# Shuffle the dataset\n",
    "balanced_dataset = balanced_dataset.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset.to_csv('data/full_clean_metabolism_ds.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
